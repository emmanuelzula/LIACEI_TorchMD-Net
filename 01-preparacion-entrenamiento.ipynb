{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddc347e1-0950-4c1c-9fa4-ed52785ff7fb",
   "metadata": {},
   "source": [
    "# Conversión de archivo .data a archivo .xyz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9964c1-27a5-4ebf-87f9-52720ec11b58",
   "metadata": {},
   "source": [
    "Este notebook esta hecho de tal manera que solamente se necesita este notebook y la base de datos .data en la misma carpeta. El procesamiento, la creacion de carpetas y de archivos se maneja internamente en el notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd5ec6f-0ebf-438c-b559-8dd88530a62b",
   "metadata": {},
   "source": [
    "Debido a que el programa TorchMD-Net esta preparado para usar unidades de posición [ $\\AA$], de fuerza,  [$\\frac{eV}{\\AA}$] y energía [eV]. Introducir otras unidades afecta de forma negativa la precisión de los resultados obtenidos. Transformaremos los datos del dataset original a las unidades esperadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b679fbf-8c6a-40f3-ad26-d4a5c3df82e6",
   "metadata": {},
   "source": [
    "Establecemos el nombre del archivo que contiene nuestros datos .data sin la extensión, esto para poder buscar el dataset y definir nombres de archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa09203-bdc1-43ef-b940-e23c70db91a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_data= \"input_bo222-200k-1173k\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27dac70-5620-49fd-9d90-c7172d1c5baf",
   "metadata": {},
   "source": [
    "Importamos los modulos necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a4b222-afe7-4864-b025-f104f6d04c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86862a52-b64c-43d9-91df-a3931e9d5814",
   "metadata": {},
   "source": [
    "Creamos las carpetas que necesitamos para el procesamiento del dataset, de existir las eliminamos y las volvemos a crear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec09bd0-abca-4bcd-b01b-bff14db4b1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carpetas del procesamiento del dataset\n",
    "carpetas = [\"originales\", \"procesados\", \"temp\"]\n",
    "carpeta_principal = \"construccion-dataset\"\n",
    "\n",
    "def crear_carpeta(carpeta):\n",
    "    ruta_carpeta = os.path.join(carpeta_principal, carpeta)\n",
    "    os.makedirs(ruta_carpeta)\n",
    "    print(f\"La carpeta '{ruta_carpeta}/' ha sido creada.\")\n",
    "\n",
    "# Verificar y eliminar la carpeta principal si existe\n",
    "if os.path.exists(carpeta_principal):\n",
    "    shutil.rmtree(carpeta_principal)\n",
    "    print(f\"La carpeta '{carpeta_principal}/' existía y ha sido eliminada junto con su contenido.\")\n",
    "\n",
    "# Crear la carpeta principal de nuevo\n",
    "os.makedirs(carpeta_principal)\n",
    "print(f\"La carpeta '{carpeta_principal}/' ha sido creada de nuevo.\")\n",
    "\n",
    "# Crear las carpetas dentro de la carpeta principal\n",
    "for carpeta in carpetas:\n",
    "    crear_carpeta(carpeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc8f1c0-b4d5-405c-90a0-12cef4c79463",
   "metadata": {},
   "source": [
    "Devido a las unidades manejadas por el modelo, se recurre a convertir los datos al formato .xyz ya que este es un estándar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41229dcf-2535-4f3e-8fd7-2c91a6064741",
   "metadata": {},
   "source": [
    "Notemos que los datos de los cuales se obtendran los rasgos son: la posición de los átomos del arreglo y  su números átomicos. En cambio los targets son la energía y las fuerzas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaede37d-ae4e-4d71-96ed-419091bdcb27",
   "metadata": {},
   "source": [
    "Convertimos el archivo .data a .xyz frame a frame, notemos que convertirmos las unidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811cea1a-bfcf-489c-b9ed-d59d219cf7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factores de conversión\n",
    "HARTREE_TO_EV=27.21138602\n",
    "HA_BO_TO_EV_ANGS=51.422067137\n",
    "\n",
    "# Abrir archivo\n",
    "with open(dataset_data+\".data\", \"r\") as archivo:\n",
    "    md_step=0\n",
    "    # Iterar linea por linea\n",
    "    for linea in archivo:\n",
    "        # Convertir linea de texto a una lista python\n",
    "        linea=linea.split()        \n",
    "        if linea[0]==\"begin\":\n",
    "            numero_de_atomos=0\n",
    "            frame_atoms=\"\"\n",
    "        if linea[0]==\"atom\":\n",
    "            numero_de_atomos=numero_de_atomos+1\n",
    "            line_pos=[linea[1],linea[2],linea[3]]\n",
    "            line_type=linea[4]\n",
    "            line_force=[linea[7],linea[8],linea[9]]\n",
    "            line_force = [float(elemento) * HA_BO_TO_EV_ANGS for elemento in line_force]\n",
    "            line_pos = [float(val) for val in line_pos]\n",
    "            line_force = [float(val) for val in line_force]\n",
    "            line_data = f\"{line_type:>2}{line_pos[0]:>20.10f}{line_pos[1]:>20.10f}{line_pos[2]:>20.10f}{line_force[0]:>20.10f}{line_force[1]:>20.10f}{line_force[2]:>20.10f}\\n\"\n",
    "\n",
    "            frame_atoms=frame_atoms+line_data\n",
    "        if linea[0]=='energy':\n",
    "            frame_energy=float(linea[1])*HARTREE_TO_EV\n",
    "            frame_energy = float(frame_energy)\n",
    "\n",
    "        if linea[0]=='charge':\n",
    "            continue\n",
    "        if linea[0]==\"end\":\n",
    "\n",
    "            frame=f\"{numero_de_atomos}\\n\"\n",
    "            frame = frame + f\"MD_Step: {md_step} Total_energy = {frame_energy:.10f}\\n\"\n",
    "            frame=frame+frame_atoms\n",
    "\n",
    "            md_step=md_step+1\n",
    "\n",
    "            with open(f\"construccion-dataset/originales/{dataset_data}.xyz\", \"a\") as file:\n",
    "                file.write(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf5fc25-9ec4-4981-84bd-5aa50f5c0737",
   "metadata": {},
   "source": [
    "## Conversión archivo .xyz a archivo .h5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67613fa-ab3a-4bd5-867a-973495f44254",
   "metadata": {},
   "source": [
    "El código ofrece posibilidades para nuevos datos, formatos .npy y .h5, en este notebook se escoje el formato .h5 debido a que se puede guardar el dataset completo en un solo archivo, cosa que no sucede con el formato .npy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7e809c-962d-411c-9cf3-3d627f025ea4",
   "metadata": {},
   "source": [
    "Para comprobar el correcto levantamiento de nuestros datos convertimos el archivo .xyz a un achivo .h5 con el cual podamos trabajar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373c0b09-0db2-499f-a0b4-9b7a36c5c128",
   "metadata": {},
   "source": [
    "Iteramos linea por linea el archivo .xyz y separamos los datos en archivos .dat, esto para no guardar los datos en ram y acceder a ellos en cada iteración lo cual hace muy pesado el procesamiento del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2278104b-507c-43fa-8842-7c3e7194bb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_de_atomos=0\n",
    "lista_num_atomos_en_muestras=[]\n",
    "with open(f\"construccion-dataset/originales/{dataset_data}.xyz\", \"r\") as archivo:\n",
    "    for linea in archivo:\n",
    "        linea=linea.split()\n",
    "        if len(linea)==1:\n",
    "            numero_de_atomos=0\n",
    "            frame_pos=\"\"\n",
    "            frame_type=\"\"\n",
    "            frame_force=\"\"\n",
    "            num_atomos_frame=linea[0]\n",
    "        if len(linea)==5:\n",
    "            frame_energy=float(linea[-1])\n",
    "        if len(linea)==7:\n",
    "            numero_de_atomos=numero_de_atomos+1\n",
    "            line_pos=[linea[1],linea[2],linea[3]]\n",
    "            line_type=[linea[0]]\n",
    "            line_force=[linea[4],linea[5],linea[6]]           \n",
    "\n",
    "            line_pos = \" \".join(str(elemento) for elemento in line_pos)+ \"\\n\"\n",
    "            frame_pos=frame_pos+line_pos\n",
    "\n",
    "            line_type = \" \".join(str(elemento) for elemento in line_type)+ \"\\n\"\n",
    "            frame_type=frame_type+line_type\n",
    "\n",
    "            line_force = \" \".join(str(elemento) for elemento in line_force)+ \"\\n\"\n",
    "            frame_force=frame_force+line_force\n",
    "\n",
    "        if int(numero_de_atomos)==int(num_atomos_frame):\n",
    "            \n",
    "            with open(f\"construccion-dataset/temp/energy_{numero_de_atomos}.dat\", \"a\") as file:\n",
    "                file.write(str(frame_energy) + \"\\n\")\n",
    "                \n",
    "            with open(f\"construccion-dataset/temp/pos_{numero_de_atomos}.dat\", \"a\") as file:\n",
    "                file.write(frame_pos)\n",
    "                \n",
    "            with open(f\"construccion-dataset/temp/type_{numero_de_atomos}.dat\", \"a\") as file:\n",
    "                file.write(frame_type)\n",
    "                \n",
    "            with open(f\"construccion-dataset/temp/force_{numero_de_atomos}.dat\", \"a\") as file:\n",
    "                file.write(frame_force)\n",
    "\n",
    "            lista_num_atomos_en_muestras.append(numero_de_atomos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9912e264-7220-4da7-b37e-999c18f32f64",
   "metadata": {},
   "source": [
    "Generamos una lista con el numero de atomos en cada frame y un diccionario con el tamaño de frame diferentes y el numero de frames con ese tamaño. Esto nos servira para acomodar las dimensiones de nuestros numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd054a2-37b9-4097-b7dd-bf9b111a1ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_atomos_repeticiones = {}\n",
    "num_atomos_unicos = list(set(lista_num_atomos_en_muestras))\n",
    "\n",
    "# Iterar sobre la lista\n",
    "for elemento in lista_num_atomos_en_muestras:\n",
    "    # Verificar si el elemento ya está en el diccionario\n",
    "    if elemento in num_atomos_repeticiones:\n",
    "        # Si está presente, incrementar el contador\n",
    "        num_atomos_repeticiones[elemento] += 1\n",
    "    else:\n",
    "        # Si no está presente, agregarlo al diccionario con contador 1\n",
    "        num_atomos_repeticiones[elemento] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24daffc4-8425-46d7-9273-5796f6c87cd3",
   "metadata": {},
   "source": [
    "Levantamos los datos de los archivos .dat, los cargamos en numpy arrays y los redimensionamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0c306b-4bcb-4e13-93f6-c0f9e28b30e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargar_datos(archivo):\n",
    "    if \"type\" in archivo:\n",
    "        # Cargar los datos del archivo en un numpy array\n",
    "        with open(archivo, 'r') as f:\n",
    "            # Utilizar readlines() para leer todas las líneas del archivo\n",
    "            contenido = f.readlines()\n",
    "            # Eliminar los saltos de línea y convertir cada línea en una cadena\n",
    "            datos = [linea.strip() for linea in contenido]\n",
    "            # Convertir la lista de cadenas en un numpy array\n",
    "            data = np.array(datos, dtype=object)\n",
    "    else:\n",
    "        # Cargar datos desde el archivo usando numpy.loadtxt\n",
    "        data = np.loadtxt(archivo)\n",
    "    return data\n",
    "    \n",
    "for num_atomos in num_atomos_unicos:\n",
    "    # Lista de nombres de archivos\n",
    "    archivos = [f\"construccion-dataset/temp/energy_{num_atomos}.dat\", f\"construccion-dataset/temp/type_{num_atomos}.dat\", f\"construccion-dataset/temp/pos_{num_atomos}.dat\", f\"construccion-dataset/temp/force_{num_atomos}.dat\"]\n",
    "    \n",
    "    # Crear una lista de arrays utilizando la función cargar_datos\n",
    "    arrays = [cargar_datos(archivo) for archivo in archivos]\n",
    "\n",
    "    # Asignar los arrays a variables específicas de forma dinámica\n",
    "    for i, nombre_array in enumerate(['energy', 'types', 'pos', 'forces']):\n",
    "        variable_name = f\"{nombre_array}_{num_atomos}\"\n",
    "        if nombre_array == 'energy':\n",
    "            globals()[variable_name]=np.reshape(arrays[i],(num_atomos_repeticiones[num_atomos]))\n",
    "        if nombre_array == 'types':\n",
    "            globals()[variable_name]=np.reshape(arrays[i],(num_atomos_repeticiones[num_atomos],num_atomos))\n",
    "        if nombre_array == 'pos':\n",
    "            globals()[variable_name]=np.reshape(arrays[i],(num_atomos_repeticiones[num_atomos],num_atomos,3))\n",
    "        if nombre_array == 'forces':\n",
    "            globals()[variable_name]=np.reshape(arrays[i],(num_atomos_repeticiones[num_atomos],num_atomos,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87158a3-eeb2-4b9b-8994-b7f499269dca",
   "metadata": {},
   "source": [
    "Guardamos los arrays en un archivo .h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5777f6b-9d17-4883-a5e2-d9daf9572bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_h5=h5py.File(f\"construccion-dataset/originales/{dataset_data}-original.h5\", \"w\")\n",
    "\n",
    "for num_atomos in num_atomos_unicos:\n",
    "    group = archivo_h5.create_group(f\"{num_atomos}_atoms\")\n",
    "    for nombre_array in ['energy', 'types', 'pos', 'forces']:\n",
    "        array = f\"{nombre_array}_{num_atomos}\"\n",
    "        group.create_dataset(nombre_array, data=globals()[array])    \n",
    "\n",
    "archivo_h5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c85afb-1e9c-435e-99d8-3221fcf8ae79",
   "metadata": {},
   "source": [
    "El codigo es complicado debido a que esta preparado para funcionar para un dataset con arreglos con distinto número de átomos. El resto del notebook no esta optimizado para ese caso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9f97d3-87f0-4ac6-874d-b3152c30e4cf",
   "metadata": {},
   "source": [
    "# Contraste entre archivo .xyz y .h5 (originales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfce7306",
   "metadata": {},
   "source": [
    "Funciones para leer un archivo e imprimir un frame especifico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20671ea-1e8e-483d-baed-5e204378f9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprimir_muestra_h5(ruta_archivo_h5, grupo, muestra):\n",
    "    import h5py\n",
    "    archivo_h5 = h5py.File(ruta_archivo_h5, \"r\")\n",
    "    grupo_actual = archivo_h5[grupo]\n",
    "    num_atoms_frame = len(grupo_actual[\"types\"][muestra])\n",
    "    frame = f\"{num_atoms_frame}\\n\"\n",
    "    frame = frame + f\"MD_Step: {muestra} Total_energy = {grupo_actual['energy'][muestra]:.10f}\\n\"\n",
    "    for i in range(num_atoms_frame):\n",
    "        if str(type(grupo_actual[\"types\"][muestra][i]))==\"<class 'bytes'>\":\n",
    "            line_type = grupo_actual[\"types\"][muestra][i].decode()\n",
    "        else:\n",
    "            line_type = grupo_actual[\"types\"][muestra][i]\n",
    "        line_x = grupo_actual[\"pos\"][muestra][i][0]\n",
    "        line_y = grupo_actual[\"pos\"][muestra][i][1]\n",
    "        line_z = grupo_actual[\"pos\"][muestra][i][2]\n",
    "        if \"forces\" in grupo_actual.keys():\n",
    "            line_fx = grupo_actual[\"forces\"][muestra][i][0]\n",
    "            line_fy = grupo_actual[\"forces\"][muestra][i][1]\n",
    "            line_fz = grupo_actual[\"forces\"][muestra][i][2]\n",
    "        else:\n",
    "            line_fx = 0\n",
    "            line_fy = 0\n",
    "            line_fz = 0\n",
    "        # Formatea la cadena con manejo de valores None\n",
    "        linea = \"{:>2}{:>20.10f}{:>20.10f}{:>20.10f}{:>20.10f}{:>20.10f}{:>20.10f}\".format(\n",
    "            line_type,\n",
    "            line_x, \n",
    "            line_y, \n",
    "            line_z,\n",
    "            line_fx, \n",
    "            line_fy, \n",
    "            line_fz\n",
    "        )\n",
    "        frame = frame + linea + \"\\n\"\n",
    "    print(frame)\n",
    "    archivo_h5.close()\n",
    "\n",
    "def imprimir_muestra_xyz(file_path, indice_muestra_deseada):\n",
    "    with open(file_path, 'r') as archivo:\n",
    "        conteo_muestras = 0\n",
    "\n",
    "        for linea in archivo:\n",
    "            if len(linea.split()) == 1:\n",
    "                if conteo_muestras==indice_muestra_deseada:\n",
    "                    frame=linea\n",
    "                else:\n",
    "                    pass\n",
    "                numero_de_atomos=0\n",
    "                num_atomos_frame=linea\n",
    "            if len(linea.split()) == 5:\n",
    "                if conteo_muestras==indice_muestra_deseada:\n",
    "                    frame=frame+linea\n",
    "                else:\n",
    "                    pass               \n",
    "            if len(linea.split()) == 7:\n",
    "                if conteo_muestras==indice_muestra_deseada:\n",
    "                    frame=frame+linea\n",
    "                else:\n",
    "                    pass\n",
    "                numero_de_atomos=numero_de_atomos+1\n",
    "            if int(numero_de_atomos) == int(num_atomos_frame):\n",
    "                if conteo_muestras==indice_muestra_deseada:\n",
    "                    print(frame)\n",
    "                else:\n",
    "                    pass\n",
    "                conteo_muestras=conteo_muestras+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7ca5a6",
   "metadata": {},
   "source": [
    "Definimos el frame a corroborar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7cc2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "muestra=10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28653044",
   "metadata": {},
   "source": [
    "Imprimimos el frame del archivo .xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9583c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imprimir_muestra_xyz(f\"construccion-dataset/originales/{dataset_data}.xyz\", muestra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d445b86e",
   "metadata": {},
   "source": [
    "Imprimimos el frame del archivo .h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b9e2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "imprimir_muestra_h5(f\"construccion-dataset/originales/{dataset_data}-original.h5\", \"222_atoms\", muestra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4bdce7-5580-45e0-a0c0-acb72e30ffe2",
   "metadata": {},
   "source": [
    "# Transormación del dataset para TorchMD-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bdd401-7215-4b25-bcde-9b7b8ba8039c",
   "metadata": {},
   "source": [
    "Hasta ahora transformamos los datos originales a un archivo .xyz para establecer un formato en común, después los convertimos al formato .h5 el cual es el formato que utiliza TorchMD-Net. Todo estas tranformaciónes tiene como fin dar certeza al correcto funcionamiento del procesamiento y no heredar errores a pasos futuros.\n",
    "\n",
    "Es en este momento dónde vamos a transformar los datos a unos que puedan ser utilizados por el código."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c42d625-f193-43c1-a51f-faf3a2977d31",
   "metadata": {},
   "source": [
    "Funciones a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103f492f-5cf9-4e34-a341-561444d97b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para intercambiar el elemento atomico por su numero atomico\n",
    "def periodic_table(input_elemento):\n",
    "    tabla_periodica = {\"H\": 1, \"O\": 8, \"Al\": 13}\n",
    "\n",
    "    if isinstance(input_elemento, str):\n",
    "        # Si se proporciona el símbolo del elemento\n",
    "        elemento = input_elemento.capitalize()\n",
    "        if elemento in tabla_periodica:\n",
    "            return tabla_periodica[elemento]\n",
    "        else:\n",
    "            return None\n",
    "    elif isinstance(input_elemento, int):\n",
    "        # Si se proporciona el número atómico\n",
    "        for simbolo, numero_atomico in tabla_periodica.items():\n",
    "            if numero_atomico == input_elemento:\n",
    "                return simbolo\n",
    "        # Si no se encuentra el número atómico en la tabla\n",
    "        return None\n",
    "    else:\n",
    "        # Si el tipo de entrada no es válido\n",
    "        return None\n",
    "\n",
    "# Función para inercambiar el elemento atomico por su energía atómica\n",
    "def atomics_energies(elemento_quimico):\n",
    "    energias_atomicas = {\n",
    "        1:-0.500272784191*27.21138602,\n",
    "        8:-74.9555225243*27.21138602,\n",
    "        13:-242.365764213*27.21138602,\n",
    "        \"H\":-0.500272784191*27.21138602,\n",
    "        \"O\":-74.9555225243*27.21138602,\n",
    "        \"Al\":-242.365764213*27.21138602\n",
    "    }\n",
    "    elemento = int(elemento_quimico)\n",
    "    if elemento in energias_atomicas:\n",
    "        return energias_atomicas[elemento]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a740dab-5d93-4220-9a3e-95423eec0f83",
   "metadata": {},
   "source": [
    "## Transformacion de los datos originales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0890ea09-9cf2-4971-8b2f-f405578687e5",
   "metadata": {},
   "source": [
    "TorchMD-Net requiere el número átomico y no el símbolo, además en entrenamientos anteriores se determinó que el target que genera los mejores resultados es la energia total del arreglo menos la energía de offset. Por lo que aplicamos estas correcciónes a los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f50588-464b-4cd2-95ef-76fae2eb9829",
   "metadata": {},
   "source": [
    "Iterar sobre los frames y transformar los datos segun lo requerido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccf0f1f-877c-4547-8be5-a4a53f2e7820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar archivo .h5\n",
    "dataset_original=h5py.File(f\"construccion-dataset/originales/{dataset_data}-original.h5\", \"r\")\n",
    "# Iterar sobre los grupos en el archivo\n",
    "for grupo in dataset_original.keys():\n",
    "    \n",
    "    # Obtener el grupo actual\n",
    "    grupo_actual = dataset_original[grupo]\n",
    "    num_atoms= grupo[:-6]\n",
    "    \n",
    "    # Iterar sobre la energía de cada frame en cada grupo en el archivo .h5\n",
    "    for i, frame_energy in enumerate(grupo_actual[\"energy\"]):\n",
    "        total_energy = frame_energy\n",
    "        atom_energy = sum(map(atomics_energies, [periodic_table(elemento.decode()) for elemento in grupo_actual[\"types\"][i]]))\n",
    "        atoms_frame = len(grupo_actual[\"types\"][i])\n",
    "        new_frame_energy = total_energy-atom_energy\n",
    "        with open(f\"construccion-dataset/temp/energy_new_{num_atoms}.dat\", \"a\") as file:\n",
    "            file.write(str(new_frame_energy) + \"\\n\")\n",
    "    energy_array=cargar_datos(f\"construccion-dataset/temp/energy_new_{num_atoms}.dat\")\n",
    "    globals()[f\"energy_new_{num_atomos}\"]=np.reshape(energy_array,(num_atomos_repeticiones[int(num_atomos)]))\n",
    "            \n",
    "    # Iterar sobre los simbolos atomicos de cada frame en cada grupo en el archivo .h5            \n",
    "    for i, frame_types in enumerate(grupo_actual[\"types\"]):\n",
    "        new_frame_types = [periodic_table(elemento.decode()) for elemento in frame_types]\n",
    "        with open(f\"construccion-dataset/temp/types_new_{num_atoms}.dat\", \"a\") as file:            \n",
    "            file.write(\"\\n\".join(map(str, new_frame_types)) + \"\\n\")\n",
    "            \n",
    "    types_array=cargar_datos(f\"construccion-dataset/temp/types_new_{num_atoms}.dat\")\n",
    "    globals()[f\"types_new_{num_atomos}\"]=np.reshape(types_array,(num_atomos_repeticiones[int(num_atomos)],int(num_atomos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bde82c-7bd3-4f46-8c90-05748ac58cbc",
   "metadata": {},
   "source": [
    "Crear nuevos archivos .h5 con los datos convertidos (con fuerzas y sin fuerzas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9487ebd3-d5d9-4746-90bd-f31716ccfc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_h5=h5py.File(f\"construccion-dataset/procesados/{dataset_data}.h5\", \"w\")\n",
    "archivo_h5_f=h5py.File(f\"construccion-dataset/procesados/{dataset_data}-f.h5\", \"w\")\n",
    "\n",
    "for num_atomos in num_atomos_unicos:\n",
    "    \n",
    "    group = archivo_h5.create_group(f\"{num_atomos}_atoms\")\n",
    "    group.create_dataset(\"pos\", data=dataset_original[f\"{num_atomos}_atoms\"][\"pos\"])\n",
    "    group.create_dataset(\"types\", data=globals()[f\"types_new_{num_atomos}\"][:].astype(np.int64))\n",
    "    group.create_dataset(\"energy\", data=globals()[f\"energy_new_{num_atomos}\"])\n",
    "    \n",
    "    group_f = archivo_h5_f.create_group(f\"{num_atomos}_atoms\")\n",
    "    group_f.create_dataset(\"pos\", data=np.array(dataset_original[f\"{num_atomos}_atoms\"][\"pos\"]))\n",
    "    group_f.create_dataset(\"types\", data=globals()[f\"types_new_{num_atomos}\"][:].astype(np.int64))\n",
    "    group_f.create_dataset(\"energy\", data=globals()[f\"energy_new_{num_atomos}\"])\n",
    "    group_f.create_dataset(\"forces\", data=dataset_original[f\"{num_atomos}_atoms\"][\"forces\"])\n",
    "\n",
    "archivo_h5.close()\n",
    "archivo_h5_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2841ec-f88c-4695-9dba-2c9666a5ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_original.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c458a064-d078-4834-922a-a157a2f24905",
   "metadata": {},
   "source": [
    "Guardar los arrays en archivos .npy\n",
    "```python\n",
    "for num_atomos in num_atomos_unicos:\n",
    "    for nombre_array in ['energy', 'types', 'pos', 'forces']:\n",
    "        array = f\"{nombre_array}_{num_atomos}\"\n",
    "        np.save(f\"construccion-dataset/originales/{array}.npy\",globals()[array])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf008bac-357e-407b-8306-00efc6cb517c",
   "metadata": {},
   "source": [
    "# Contraste archivo .h5 original contra archivo .h5 convertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef26868f-5d71-42a1-b66c-6f93d5ca5dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "muestra=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0656dd94-189b-48b7-be60-59791f65a8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imprimir_muestra_h5(f\"construccion-dataset/originales/{dataset_data}-original.h5\", \"222_atoms\", muestra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2931088-8812-4c5a-9341-27f701d679eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imprimir_muestra_h5(f\"construccion-dataset/procesados/{dataset_data}-f.h5\", \"222_atoms\", muestra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fed448b-aebb-49f6-a555-89582be2e471",
   "metadata": {},
   "source": [
    "# Preparación del entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c3de0a-149b-42fc-9d5b-5585f218bd87",
   "metadata": {},
   "source": [
    "Creamos las carpetas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ac89fc-6bd3-4636-8610-6e6eb0b87c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombres de las carpetas que quieres crear\n",
    "nombres_carpetas = ['input', 'output']\n",
    "\n",
    "# Crear las carpetas si no existen y obtener las rutas relativas\n",
    "rutas_carpetas = []\n",
    "for carpeta in nombres_carpetas:\n",
    "    os.makedirs(carpeta, exist_ok=True)\n",
    "    rutas_carpetas.append(carpeta)\n",
    "\n",
    "print(\"Carpetas creadas:\")\n",
    "for carpeta in rutas_carpetas:\n",
    "    print(carpeta+\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c9b205-0176-43be-8d68-9949774444b6",
   "metadata": {},
   "source": [
    "Podemos heredar los indices de los conjuntos de datos (train, validation, test) de un archivo .csv o npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bcc9e3-c9eb-4aff-97f2-295b5fd24eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def archivo_csv():\n",
    "    # Obtener la ruta absoluta del directorio actual\n",
    "    directorio_actual = os.getcwd()\n",
    "    \n",
    "    # Buscar archivos en el directorio actual\n",
    "    archivos_en_directorio = os.listdir(directorio_actual)\n",
    "    for archivo in archivos_en_directorio:\n",
    "        if os.path.isfile(archivo) and archivo.endswith('.csv'):\n",
    "            return True\n",
    "    \n",
    "    # Si no se encuentra ningún archivo .csv\n",
    "    return False\n",
    "\n",
    "def archivo_npz():\n",
    "    # Obtener la ruta absoluta del directorio actual\n",
    "    directorio_actual = os.getcwd()\n",
    "    \n",
    "    # Buscar archivos en el directorio actual\n",
    "    archivos_en_directorio = os.listdir(directorio_actual)\n",
    "    for archivo in archivos_en_directorio:\n",
    "        if os.path.isfile(archivo) and archivo.endswith('.npz'):\n",
    "            return True\n",
    "    \n",
    "    # Si no se encuentra ningún archivo .npz\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fe8865-07ea-4c77-af68-fa2afe6e3f6f",
   "metadata": {},
   "source": [
    "Si tenemos un achivo .csv lo convertimo a .npz con las caracteristicas necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a003ad1-ab0c-4839-a580-3e27a37cd78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if archivo_csv():\n",
    "    \n",
    "    # Obtener la ruta absoluta del directorio actual\n",
    "    directorio_actual = os.getcwd()\n",
    "    \n",
    "    # Buscar archivos en el directorio actual\n",
    "    archivos_en_directorio = os.listdir(directorio_actual)\n",
    "    for archivo in archivos_en_directorio:\n",
    "        if os.path.isfile(archivo) and archivo.endswith('.csv'):\n",
    "            # Si se encuentra un archivo .csv, cargarlo y devolver el DataFrame\n",
    "            archivo_csv_ = pd.read_csv(archivo)\n",
    "            \n",
    "    # Convertir la columna \"ids\" a tipo de datos int\n",
    "    archivo_csv_[\"ids\"] = archivo_csv_[\"ids\"].astype(int)\n",
    "    \n",
    "    # Definir los tamaños de los conjuntos\n",
    "    test_size = int(len(archivo_csv_) * 0.1)\n",
    "    val_size = int(len(archivo_csv_) * 0.09)\n",
    "    \n",
    "    # Crear el diccionario para almacenar los conjuntos\n",
    "    splits = {}\n",
    "    splits['idx_test'] = archivo_csv_[\"ids\"][:test_size].values\n",
    "    splits['idx_val'] = archivo_csv_[\"ids\"][test_size:test_size+val_size].values\n",
    "    splits['idx_train'] = archivo_csv_[\"ids\"][test_size+val_size:].values\n",
    "    \n",
    "    # Guardar los arrays en un archivo .npz\n",
    "    np.savez(\"input/splits.npz\", idx_train=splits['idx_train'], idx_val=splits['idx_val'], idx_test=splits['idx_test'])\n",
    "    print(\"Se transformó el archivo .csv a .npz y se movió a input/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23db2005-0535-4bcb-88df-535371324d61",
   "metadata": {},
   "source": [
    "Si tenemos un archivo .npz ya listo, simplemente lo copiamos a la carpeta correspondiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad32788-9059-4153-bd60-acf12d0ce4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if archivo_npz():\n",
    "    # Obtener la ruta absoluta del directorio actual\n",
    "    directorio_actual = os.getcwd()\n",
    "    \n",
    "    # Buscar archivos en el directorio actual\n",
    "    archivos_en_directorio = os.listdir(directorio_actual)\n",
    "    \n",
    "    # Verificar si el archivo especificado está en el directorio\n",
    "    if \"splits.npz\" in archivos_en_directorio:\n",
    "\n",
    "        # Nombre del archivo a mover\n",
    "        nombre_archivo = \"splits.npz\"\n",
    "        \n",
    "        # Directorio actual\n",
    "        directorio_origen = os.getcwd()\n",
    "        directorio_destino = os.path.join(os.getcwd(), \"input\")\n",
    "        \n",
    "        # Ruta completa del archivo de origen y destino\n",
    "        ruta_origen = os.path.join(directorio_origen, nombre_archivo)\n",
    "        ruta_destino = os.path.join(directorio_destino, nombre_archivo)\n",
    "        \n",
    "        # Verificar si el archivo existe en el directorio actual\n",
    "        if os.path.exists(ruta_origen):\n",
    "            # Verificar si el directorio de destino existe, si no, crearlo\n",
    "            if not os.path.exists(directorio_destino):\n",
    "                os.makedirs(directorio_destino)\n",
    "            \n",
    "            # Mover el archivo\n",
    "            shutil.move(ruta_origen, ruta_destino)\n",
    "            print(f\"El archivo '{nombre_archivo}' se ha movido correctamente a la carpeta 'input'.\")\n",
    "        else:\n",
    "            print(f\"No se encontró el archivo '{nombre_archivo}' en el directorio actual.\")\n",
    "    else:\n",
    "        print(\"Revisa que tu archivo tenga las caracteristicas requeridas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ca823d-84dd-429a-bc34-7d6dd4cd5b94",
   "metadata": {},
   "source": [
    "Si no tenemos ningun archivo, lo generamos nosotros. Debemos tener cuidado con el número de frames, en este caso se recupera el conteo del procesamiento del archivo .data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075c6736-bbfc-408f-974a-18890e15e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not archivo_csv() and not archivo_npz():\n",
    "    numero_frames = md_step\n",
    "    np.random.seed(42)\n",
    "    numeros = np.arange(numero_frames)\n",
    "    \n",
    "    # Permutar aleatoriamente los números\n",
    "    numeros_aleatorios = np.random.permutation(numeros)\n",
    "    \n",
    "    # Calcular las longitudes de los conjuntos de datos\n",
    "    total_elementos = len(numeros_aleatorios)\n",
    "    num_elementos_test = int(0.1 * total_elementos)\n",
    "    num_elementos_train = int(0.81 * total_elementos)\n",
    "    num_elementos_val = int(0.09 * total_elementos)\n",
    "    \n",
    "    # Dividir el array en tres conjuntos según las proporciones especificadas\n",
    "    idx_test, idx_val, idx_train = np.split(numeros_aleatorios, [num_elementos_test, num_elementos_test + num_elementos_val])\n",
    "    \n",
    "    np.savez(\"input/splits.npz\", idx_test=idx_test, idx_train=idx_train, idx_val=idx_val)\n",
    "\n",
    "    print(\"Como no se encontraron archivos .npz o .csv se generaron los ids de cada conjunto de datos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c1f685-1a53-488c-8445-944c95afadc0",
   "metadata": {},
   "source": [
    "Copiamos el dataset procesado el con el cual entrenaremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be90675a-259b-4dd0-aa5f-a488b3aacbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio actual\n",
    "directorio_actual = os.getcwd()\n",
    "\n",
    "# Rutas de origen y destino (relativas al directorio actual)\n",
    "ruta_origen_relativa = f\"construccion-dataset/procesados/{dataset_data}-f.h5\"\n",
    "ruta_destino_relativa = \"input\"\n",
    "\n",
    "# Rutas completas de origen y destino\n",
    "ruta_origen = os.path.join(directorio_actual, ruta_origen_relativa)\n",
    "ruta_destino = os.path.join(directorio_actual, ruta_destino_relativa)\n",
    "\n",
    "# Copiar el archivo\n",
    "shutil.copy(ruta_origen, ruta_destino)\n",
    "\n",
    "# Verificar que el archivo se ha copiado correctamente\n",
    "archivo_copiado = os.path.join(ruta_destino, os.path.basename(ruta_origen))\n",
    "\n",
    "if os.path.exists(archivo_copiado):\n",
    "    print(f\"El archivo se ha copiado correctamente a {archivo_copiado}\")\n",
    "else:\n",
    "    print(\"Hubo un problema al copiar el archivo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc52d3d-1dbc-4166-8abb-f48615afb8f2",
   "metadata": {},
   "source": [
    "Generamos los archivos .xyz correspondientes a cada subconjunto de datos para poder saber que datos se utilizaron en cada subconjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a9e844-8b0a-42ad-a0a0-cecaf5d0ebdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = np.load(\"input/splits.npz\")\n",
    "idx_train = np.sort(splits['idx_train'])\n",
    "idx_val = np.sort(splits['idx_val'])\n",
    "idx_test = np.sort(splits['idx_test'])\n",
    "\n",
    "with open(f\"construccion-dataset/originales/{dataset_data}.xyz\", 'r') as archivo:\n",
    "    \n",
    "    conteo_muestras = 0\n",
    "    \n",
    "    for linea in archivo:\n",
    "        if len(linea.split()) == 1:\n",
    "            frame=linea\n",
    "            numero_de_atomos=0\n",
    "            num_atomos_frame=linea\n",
    "        if len(linea.split()) == 5:\n",
    "            frame=frame+linea             \n",
    "        if len(linea.split()) == 7:\n",
    "            frame=frame+linea\n",
    "            numero_de_atomos=numero_de_atomos+1\n",
    "        if int(numero_de_atomos) == int(num_atomos_frame):\n",
    "            frame=frame+linea\n",
    "            indice= conteo_muestras\n",
    "            if indice in idx_train:\n",
    "                with open(f\"construccion-dataset/originales/{dataset_data}-train.xyz\", 'a') as output_file:\n",
    "                    output_file.write(frame)\n",
    "            if indice in idx_val:\n",
    "                with open(f\"construccion-dataset/originales/{dataset_data}-val.xyz\", 'a') as output_file:\n",
    "                    output_file.write(frame)\n",
    "            if indice in idx_test:\n",
    "                with open(f\"construccion-dataset/originales/{dataset_data}-test.xyz\", 'a') as output_file:\n",
    "                    output_file.write(frame)\n",
    "                \n",
    "            conteo_muestras += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988b3ee4-4343-479c-bda4-1e00d0c63c49",
   "metadata": {},
   "source": [
    "Definimos la configuración del entrenamiento y la guardamos en un archivo .yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5439bbc2-37a0-4c21-8bb0-6cdbb08b519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "configuracion = f\"\"\"activation: silu\n",
    "aggr: add\n",
    "atom_filter: -1\n",
    "attn_activation: silu\n",
    "batch_size: 32\n",
    "coord_files: null\n",
    "cutoff_lower: 0.0\n",
    "cutoff_upper: 6.35\n",
    "dataset: HDF5\n",
    "dataset_arg: null\n",
    "dataset_root: input/{dataset_data}-f.h5\n",
    "derivative: True\n",
    "distance_influence: both\n",
    "early_stopping_patience: 500\n",
    "ema_alpha_neg_dy: 1.0\n",
    "ema_alpha_y: 1.0\n",
    "embed_files: null\n",
    "embedding_dimension: 128\n",
    "energy_files: null\n",
    "y_weight: 0.0001\n",
    "force_files: null\n",
    "neg_dy_weight: 1.0\n",
    "inference_batch_size: 4\n",
    "load_model: null\n",
    "log_dir: logs/\n",
    "lr: 0.0007\n",
    "lr_factor: 0.5\n",
    "lr_min: 1.0e-07\n",
    "lr_patience: 5\n",
    "lr_warmup_steps: 10000\n",
    "max_num_neighbors: 140\n",
    "max_z: 100\n",
    "model: equivariant-transformer\n",
    "neighbor_embedding: true\n",
    "ngpus: -1\n",
    "num_epochs: 1000\n",
    "num_heads: 8\n",
    "num_layers: 6\n",
    "num_nodes: 1\n",
    "num_rbf: 32\n",
    "num_workers: 6\n",
    "output_model: Scalar\n",
    "precision: 32\n",
    "rbf_type: expnorm\n",
    "redirect: false\n",
    "reduce_op: add\n",
    "save_interval: 10\n",
    "seed: 42\n",
    "splits: input/splits.npz\n",
    "standardize: false\n",
    "test_interval: 10\n",
    "test_size: 0.1\n",
    "train_size: 0.81\n",
    "trainable_rbf: false\n",
    "val_size: 0.09\n",
    "weight_decay: 0.0\n",
    "\"\"\"\n",
    "\n",
    "# Ruta del archivo YAML de salida\n",
    "ruta_salida = f\"input/{dataset_data}.yaml\"\n",
    "\n",
    "# Guardar el texto como archivo YAML sin módulos adicionales\n",
    "with open(ruta_salida, 'w') as archivo:\n",
    "    archivo.write(configuracion)\n",
    "\n",
    "print(f\"El archivo YAML se ha guardado correctamente en: {ruta_salida}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c04df2-cf14-4b4b-a422-98039c89d902",
   "metadata": {},
   "source": [
    "Definimos el script de entrenamiento que sera ejecutado por nohup, es importante tomar en cuenta que el comando CUDA_VISIBLE_DEVICES Hace referencia a las gpu's que se utilizaran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85ebecf-ca9d-4c97-bb67-48159fae2c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "comando_principal=f\"CUDA_VISIBLE_DEVICES=0,1,2,3 torchmd-train --conf {ruta_salida} --log-dir output/\"\n",
    "\n",
    "texto_script=f\"\"\"#!/bin/bash\n",
    "\n",
    "# Archivo para guardar la información\n",
    "output_file=\"output/informacion_entrenamiento.txt\"\n",
    "\n",
    "# Guardar el comando de ejecución y la hora de inicio\n",
    "echo \"Comando de ejecución: {comando_principal}\" > \"$output_file\"\n",
    "start_time=$(date +\"%Y-%m-%d %H:%M:%S\")\n",
    "echo \"Inicio del entrenamiento: $start_time\" >> \"$output_file\"\n",
    "\n",
    "# Ejecutar el comando de entrenamiento\n",
    "{comando_principal}\n",
    "\n",
    "# Guardar la hora de finalización\n",
    "end_time=$(date +\"%Y-%m-%d %H:%M:%S\")\n",
    "echo \"Fin del entrenamiento: $end_time\" >> \"$output_file\"\n",
    "\n",
    "# Calcular la duración del entrenamiento\n",
    "start_seconds=$(date -d \"$start_time\" +%s)\n",
    "end_seconds=$(date -d \"$end_time\" +%s)\n",
    "duration_seconds=$((end_seconds - start_seconds))\n",
    "\n",
    "# Guardar la duración en el archivo\n",
    "echo \"Duración del entrenamiento: $((duration_seconds / 60)) minutos y $((duration_seconds % 60)) segundos\" >> \"$output_file\"\n",
    "\n",
    "echo \"Información del entrenamiento guardada en $output_file\"\n",
    "\"\"\"\n",
    "\n",
    "# Ruta del script de salida\n",
    "ruta_salida = \"iniciar-entrenamiento.sh\"\n",
    "\n",
    "# Guardar el texto como archivo YAML sin módulos adicionales\n",
    "with open(ruta_salida, 'w') as archivo:\n",
    "    archivo.write(texto_script)\n",
    "\n",
    "print(f\"El script se ha guardado correctamente en: {ruta_salida}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbd341a-4722-4bad-8b9b-db01c8d69209",
   "metadata": {},
   "source": [
    "# Ejecución del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74072ad5-3002-4516-ac3c-10fdbe0f6b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde26421-f0b0-4755-b732-f77ec93a6141",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Recuerda dar permiso de ejecución al script con el comando en terminal\n",
    "\n",
    "```bash\n",
    "chmod +x iniciar-entrenamiento.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e4dc0e-bcaa-4796-8ad9-60b251944848",
   "metadata": {},
   "source": [
    "Ejecución con nohup\n",
    "\n",
    "Para que el script se siga ejecutando independientemente del estado de la terminal donde se inicio se ejecuta el siguiente comando\n",
    "\n",
    "```bash\n",
    "nohup ./iniciar-entrenamiento.sh > output/salida.log 2>&1 &\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchmd-net",
   "language": "python",
   "name": "torchmd-net"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
